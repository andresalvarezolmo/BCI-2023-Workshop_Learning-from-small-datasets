{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5dc049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andresalvarezolmo/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "from skorch import NeuralNet\n",
    "from skorch.utils import to_numpy\n",
    "from sklearn.base import TransformerMixin\n",
    "from braindecode.models import EEGNetv4\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from moabb.paradigms import MotorImagery\n",
    "from moabb.datasets import Shin2017A\n",
    "from moabb.evaluations import WithinSessionEvaluation, CrossSessionEvaluation\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d109511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_clf_layers(model: nn.Sequential):\n",
    "    \"\"\"\n",
    "    Remove the classification layers from braindecode models.\n",
    "    Tested on EEGNetv4, Deep4Net (i.e. DeepConvNet), and EEGResNet.\n",
    "    \"\"\"\n",
    "    new_layers = []\n",
    "    for name, layer in model.named_children():\n",
    "        if 'classif' in name:\n",
    "            continue\n",
    "        if 'softmax' in name:\n",
    "            continue\n",
    "        new_layers.append((name, layer))\n",
    "    return nn.Sequential(OrderedDict(new_layers))\n",
    "\n",
    "\n",
    "def freeze_model(model):\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c600f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrozenNeuralNetTransformer(NeuralNet, TransformerMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            *args,\n",
    "            criterion=nn.MSELoss,  # should be unused\n",
    "            unique_name=None,  # needed for a unique digest in MOABB\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            criterion=criterion,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.initialize()\n",
    "        self.unique_name = unique_name\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self  # do nothing\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.infer(X)\n",
    "        return to_numpy(X)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return super().__repr__() + self.unique_name\n",
    "    \n",
    "def flatten_batched(X):\n",
    "    return X.reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67e89ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andresalvarezolmo/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'in_chans' is depreciated. Use 'n_chans' instead.\n",
      "  warnings.warn(\n",
      "/Users/andresalvarezolmo/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'n_classes' is depreciated. Use 'n_outputs' instead.\n",
      "  warnings.warn(\n",
      "/Users/andresalvarezolmo/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'input_window_samples' is depreciated. Use 'n_times' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# download the model from the hub:\n",
    "path_kwargs = hf_hub_download(\n",
    "    repo_id='PierreGtch/EEGNetv4',\n",
    "    filename='EEGNetv4_Cho2017/kwargs.pkl',\n",
    ")\n",
    "path_params = hf_hub_download(\n",
    "    repo_id='PierreGtch/EEGNetv4',\n",
    "    filename='EEGNetv4_Cho2017/model-params.pkl',\n",
    ")\n",
    "with open(path_kwargs, 'rb') as f:\n",
    "    kwargs = pickle.load(f)\n",
    "    module_cls = kwargs['module_cls']\n",
    "    module_kwargs = kwargs['module_kwargs']\n",
    "\n",
    "# load the model with pre-trained weights:\n",
    "torch_module = module_cls(**module_kwargs)\n",
    "torch_module.load_state_dict(torch.load(path_params, map_location='cpu'))\n",
    "embedding = freeze_model(remove_clf_layers(torch_module)).double()\n",
    "# embedding = remove_clf_layers(torch_module).double()\n",
    "\n",
    "# Integrate the model in a Scikit-learn pipeline:\n",
    "sklearn_pipeline = Pipeline([\n",
    "    ('embedding', FrozenNeuralNetTransformer(embedding, unique_name='pretrained_Cho2017')),\n",
    "    ('flatten', FunctionTransformer(flatten_batched)),\n",
    "    ('classifier', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37167e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm = MotorImagery(\n",
    "    channels=['C3', 'Cz', 'C4'],  # Same as the ones used to pre-train the embedding\n",
    "    events=['left_hand', 'right_hand'],\n",
    "    n_classes=2,\n",
    "    fmin=0.5,\n",
    "    fmax=40,\n",
    "    tmin=0,\n",
    "    tmax=3,\n",
    "    resample=128\n",
    ")\n",
    "datasets = [Shin2017A(accept=True)]\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm,\n",
    "    datasets=datasets,\n",
    "    overwrite=True,\n",
    "    suffix='demo',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8142e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shin2017A-WithinSession:   0%|          | 0/29 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "You must accept licence term to download this dataset,set accept=True when instantiating the dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipelines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdemo_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msklearn_pipeline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m results\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/evaluations/base.py:237\u001b[0m, in \u001b[0;36mBaseEvaluation.process\u001b[0;34m(self, pipelines, param_grid, postprocess_pipeline)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# (we only keep the pipeline for the first frequency band, better ideas?)\u001b[39;00m\n\u001b[1;32m    230\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m    231\u001b[0m     dataset,\n\u001b[1;32m    232\u001b[0m     pipelines,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     postprocess_pipeline\u001b[38;5;241m=\u001b[39mpostprocess_pipeline,\n\u001b[1;32m    236\u001b[0m )\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush_result(res, pipelines, process_pipeline)\n\u001b[1;32m    239\u001b[0m res_per_db\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m    241\u001b[0m         pipelines\u001b[38;5;241m=\u001b[39mpipelines, process_pipeline\u001b[38;5;241m=\u001b[39mprocess_pipeline\n\u001b[1;32m    242\u001b[0m     )\n\u001b[1;32m    243\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/evaluations/evaluations.py:443\u001b[0m, in \u001b[0;36mWithinSessionEvaluation.evaluate\u001b[0;34m(self, dataset, pipelines, param_grid, process_pipeline, postprocess_pipeline)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_learning_curve(\n\u001b[1;32m    440\u001b[0m         dataset, pipelines, process_pipeline, postprocess_pipeline\n\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(\n\u001b[1;32m    444\u001b[0m         dataset, pipelines, param_grid, process_pipeline, postprocess_pipeline\n\u001b[1;32m    445\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/evaluations/evaluations.py:158\u001b[0m, in \u001b[0;36mWithinSessionEvaluation._evaluate\u001b[0;34m(self, dataset, pipelines, param_grid, process_pipeline, postprocess_pipeline)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# get the data\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m X, y, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparadigm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_raws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_raws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpostprocess_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpostprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# iterate over sessions\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m session \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(metadata\u001b[38;5;241m.\u001b[39msession):\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/paradigms/base.py:274\u001b[0m, in \u001b[0;36mBaseProcessing.get_data\u001b[0;34m(self, dataset, subjects, return_epochs, return_raws, cache_config, postprocess_pipeline)\u001b[0m\n\u001b[1;32m    269\u001b[0m process_pipelines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_process_pipelines(\n\u001b[1;32m    270\u001b[0m     dataset, return_epochs, return_raws, postprocess_pipeline\n\u001b[1;32m    271\u001b[0m )\n\u001b[1;32m    272\u001b[0m labels_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_labels_pipeline(dataset, return_epochs, return_raws)\n\u001b[0;32m--> 274\u001b[0m data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    275\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mget_data(\n\u001b[1;32m    276\u001b[0m         subjects\u001b[38;5;241m=\u001b[39msubjects,\n\u001b[1;32m    277\u001b[0m         cache_config\u001b[38;5;241m=\u001b[39mcache_config,\n\u001b[1;32m    278\u001b[0m         process_pipeline\u001b[38;5;241m=\u001b[39mprocess_pipeline,\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m process_pipeline \u001b[38;5;129;01min\u001b[39;00m process_pipelines\n\u001b[1;32m    281\u001b[0m ]\n\u001b[1;32m    283\u001b[0m X \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    284\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/paradigms/base.py:275\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    269\u001b[0m process_pipelines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_process_pipelines(\n\u001b[1;32m    270\u001b[0m     dataset, return_epochs, return_raws, postprocess_pipeline\n\u001b[1;32m    271\u001b[0m )\n\u001b[1;32m    272\u001b[0m labels_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_labels_pipeline(dataset, return_epochs, return_raws)\n\u001b[1;32m    274\u001b[0m data \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 275\u001b[0m     \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m process_pipeline \u001b[38;5;129;01min\u001b[39;00m process_pipelines\n\u001b[1;32m    281\u001b[0m ]\n\u001b[1;32m    283\u001b[0m X \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    284\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/datasets/base.py:433\u001b[0m, in \u001b[0;36mBaseDataset.get_data\u001b[0;34m(self, subjects, cache_config, process_pipeline)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subject \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubject_list:\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid subject \u001b[39m\u001b[38;5;132;01m{:d}\u001b[39;00m\u001b[38;5;124m given\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(subject))\n\u001b[0;32m--> 433\u001b[0m     data[subject] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_single_subject_data_using_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m check_subject_names(data)\n\u001b[1;32m    439\u001b[0m check_session_names(data)\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/datasets/base.py:527\u001b[0m, in \u001b[0;36mBaseDataset._get_single_subject_data_using_cache\u001b[0;34m(self, subject, cache_config, process_pipeline)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# Load and eventually overwrite:\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cached_steps) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# last option: we don't use cache\u001b[39;00m\n\u001b[0;32m--> 527\u001b[0m     sessions_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_single_subject_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sessions_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# should not happen\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/datasets/bbci_eeg_fnirs.py:132\u001b[0m, in \u001b[0;36mBaseShin2017._get_single_subject_data\u001b[0;34m(self, subject)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_single_subject_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, subject):\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return data for a single subject.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     fname, fname_mrk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     data \u001b[38;5;241m=\u001b[39m loadmat(fname, squeeze_me\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, struct_as_record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    134\u001b[0m     mrk \u001b[38;5;241m=\u001b[39m loadmat(fname_mrk, squeeze_me\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, struct_as_record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrk\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/datasets/bbci_eeg_fnirs.py:189\u001b[0m, in \u001b[0;36mBaseShin2017.data_path\u001b[0;34m(self, subject, path, force_update, update_path, verbose, accept)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fnirs_data_path(\n\u001b[1;32m    186\u001b[0m         op\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMNE-eegfnirs-data\u001b[39m\u001b[38;5;124m\"\u001b[39m), subject, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccept\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meeg_data_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMNE-eegfnirs-data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/datasets/bbci_eeg_fnirs.py:34\u001b[0m, in \u001b[0;36meeg_data_path\u001b[0;34m(base_path, subject, accept)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m op\u001b[38;5;241m.\u001b[39misfile(op\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEEG.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m accept:\n\u001b[0;32m---> 34\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must accept licence term to download this dataset,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset accept=True when instantiating the dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m         )\n\u001b[1;32m     38\u001b[0m     downloader \u001b[38;5;241m=\u001b[39m choose_downloader(SHIN_URL, progressbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m     downloader\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverify\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: You must accept licence term to download this dataset,set accept=True when instantiating the dataset."
     ]
    }
   ],
   "source": [
    "results = evaluation.process(pipelines=dict(demo_pipeline=sklearn_pipeline))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy        f1    recall  specificity  precision\n",
      "0   0.86225  0.861143  0.862278     0.931198   0.873026\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"accuracy\": [results['score'].mean()],\n",
    "    \"f1\": [results[\"f1\"].mean()],\n",
    "    \"recall\": [results[\"recall\"].mean()],\n",
    "    \"specificity\": [results[\"specificity\"].mean()],\n",
    "    \"precision\": [results[\"precision\"].mean()]     \n",
    "    } \n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
