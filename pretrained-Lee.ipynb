{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82952a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andresalvarezolmo/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "from skorch import NeuralNet\n",
    "from skorch.utils import to_numpy\n",
    "from sklearn.base import TransformerMixin\n",
    "from braindecode.models import EEGNetv4\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from moabb.paradigms import MotorImagery\n",
    "from moabb.datasets import Zhou2016\n",
    "from moabb.evaluations import WithinSessionEvaluation, CrossSessionEvaluation\n",
    "\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf0f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_clf_layers(model: nn.Sequential):\n",
    "    \"\"\"\n",
    "    Remove the classification layers from braindecode models.\n",
    "    Tested on EEGNetv4, Deep4Net (i.e. DeepConvNet), and EEGResNet.\n",
    "    \"\"\"\n",
    "    new_layers = []\n",
    "    for name, layer in model.named_children():\n",
    "        if 'classif' in name:\n",
    "            continue\n",
    "        if 'softmax' in name:\n",
    "            continue\n",
    "        new_layers.append((name, layer))\n",
    "    return nn.Sequential(OrderedDict(new_layers))\n",
    "\n",
    "\n",
    "def freeze_model(model):\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cc5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrozenNeuralNetTransformer(NeuralNet, TransformerMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            *args,\n",
    "            criterion=nn.MSELoss,  # should be unused\n",
    "            unique_name=None,  # needed for a unique digest in MOABB\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            criterion=criterion,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.initialize()\n",
    "        self.unique_name = unique_name\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self  # do nothing\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.infer(X)\n",
    "        return to_numpy(X)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return super().__repr__() + self.unique_name\n",
    "    \n",
    "def flatten_batched(X):\n",
    "    return X.reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class RandomLogisticRegression(LogisticRegression):\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_classes = len(self.classes_)\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        self.coef_ = np.random.randn(\n",
    "            1 if n_classes == 2 else n_classes,\n",
    "            n_features\n",
    "        )\n",
    "        self.intercept_ = np.random.randn(\n",
    "            1 if n_classes == 2 else n_classes\n",
    "        )\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecb1a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# download the model from the hub:\n",
    "path_kwargs = hf_hub_download(\n",
    "    repo_id='PierreGtch/EEGNetv4',\n",
    "    filename='EEGNetv4_Lee2019_MI/kwargs.pkl',\n",
    ")\n",
    "path_params = hf_hub_download(\n",
    "    repo_id='PierreGtch/EEGNetv4',\n",
    "    filename='EEGNetv4_Lee2019_MI/model-params.pkl',\n",
    ")\n",
    "with open(path_kwargs, 'rb') as f:\n",
    "    kwargs = pickle.load(f)\n",
    "module_cls = kwargs['module_cls']\n",
    "module_kwargs = kwargs['module_kwargs']\n",
    "\n",
    "# load the model with pre-trained weights:\n",
    "torch_module = module_cls(**module_kwargs)\n",
    "torch_module.load_state_dict(torch.load(path_params, map_location='cpu'))\n",
    "embedding = freeze_model(remove_clf_layers(torch_module)).double()\n",
    "\n",
    "# Integrate the model in a Scikit-learn pipeline:\n",
    "sklearn_pipeline = Pipeline([\n",
    "    ('embedding', FrozenNeuralNetTransformer(embedding, unique_name='pretrained_Lee2019')),\n",
    "    ('flatten', FunctionTransformer(flatten_batched)),\n",
    "    ('classifier', RandomLogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ec3487",
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm = MotorImagery(\n",
    "    channels=['C3', 'Cz', 'C4'],  # Same as the ones used to pre-train the embedding\n",
    "    events=['left_hand', 'right_hand', 'feet'],\n",
    "    n_classes=3,\n",
    "    fmin=0.5,\n",
    "    fmax=40,\n",
    "    tmin=0,\n",
    "    tmax=3,\n",
    "    resample=128\n",
    ")\n",
    "datasets = [Zhou2016()]\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm,\n",
    "    datasets=datasets,\n",
    "    overwrite=True,\n",
    "    suffix='demo',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21337710",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluation.process(pipelines=dict(demo_pipeline=sklearn_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdc2fc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>time</th>\n",
       "      <th>samples</th>\n",
       "      <th>subject</th>\n",
       "      <th>session</th>\n",
       "      <th>channels</th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>dataset</th>\n",
       "      <th>pipeline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295873</td>\n",
       "      <td>0.215698</td>\n",
       "      <td>0.295960</td>\n",
       "      <td>0.646881</td>\n",
       "      <td>0.181648</td>\n",
       "      <td>0.033342</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.280766</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.282301</td>\n",
       "      <td>0.028085</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.323245</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.373028</td>\n",
       "      <td>0.022446</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.301229</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.276819</td>\n",
       "      <td>0.023878</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.237037</td>\n",
       "      <td>0.173103</td>\n",
       "      <td>0.237037</td>\n",
       "      <td>0.618519</td>\n",
       "      <td>0.146648</td>\n",
       "      <td>0.023591</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.287576</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.364279</td>\n",
       "      <td>0.026319</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.162743</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.202112</td>\n",
       "      <td>0.029106</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.252688</td>\n",
       "      <td>0.201869</td>\n",
       "      <td>0.252727</td>\n",
       "      <td>0.626836</td>\n",
       "      <td>0.177861</td>\n",
       "      <td>0.023882</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.234055</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.304353</td>\n",
       "      <td>0.031908</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.200733</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.185560</td>\n",
       "      <td>0.024413</td>\n",
       "      <td>135.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.216019</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.182844</td>\n",
       "      <td>0.022234</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.253308</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.317069</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score        f1    recall  specificity  precision      time  samples  \\\n",
       "0   0.295873  0.215698  0.295960     0.646881   0.181648  0.033342    179.0   \n",
       "1   0.320000  0.280766  0.320000     0.660000   0.282301  0.028085    150.0   \n",
       "2   0.373333  0.323245  0.373333     0.686667   0.373028  0.022446    150.0   \n",
       "3   0.380000  0.301229  0.380000     0.690000   0.276819  0.023878    150.0   \n",
       "4   0.237037  0.173103  0.237037     0.618519   0.146648  0.023591    135.0   \n",
       "5   0.340000  0.287576  0.340000     0.670000   0.364279  0.026319    150.0   \n",
       "6   0.233333  0.162743  0.233333     0.616667   0.202112  0.029106    150.0   \n",
       "7   0.252688  0.201869  0.252727     0.626836   0.177861  0.023882    151.0   \n",
       "8   0.300000  0.234055  0.300000     0.650000   0.304353  0.031908    150.0   \n",
       "9   0.288889  0.200733  0.288889     0.644444   0.185560  0.024413    135.0   \n",
       "10  0.313333  0.216019  0.313333     0.656667   0.182844  0.022234    150.0   \n",
       "11  0.313333  0.253308  0.313333     0.656667   0.317069  0.025994    150.0   \n",
       "\n",
       "   subject session  channels  n_sessions   dataset       pipeline  \n",
       "0        1       0         3           3  Zhou2016  demo_pipeline  \n",
       "1        1       1         3           3  Zhou2016  demo_pipeline  \n",
       "2        1       2         3           3  Zhou2016  demo_pipeline  \n",
       "3        2       0         3           3  Zhou2016  demo_pipeline  \n",
       "4        2       1         3           3  Zhou2016  demo_pipeline  \n",
       "5        2       2         3           3  Zhou2016  demo_pipeline  \n",
       "6        3       0         3           3  Zhou2016  demo_pipeline  \n",
       "7        3       1         3           3  Zhou2016  demo_pipeline  \n",
       "8        3       2         3           3  Zhou2016  demo_pipeline  \n",
       "9        4       0         3           3  Zhou2016  demo_pipeline  \n",
       "10       4       1         3           3  Zhou2016  demo_pipeline  \n",
       "11       4       2         3           3  Zhou2016  demo_pipeline  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0459b02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy        f1    recall  specificity  precision\n",
      "0  0.303985  0.237529  0.303996     0.651946   0.249544\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = {\n",
    "    \"accuracy\": [results['score'].mean()],\n",
    "    \"f1\": [results[\"f1\"].mean()],\n",
    "    \"recall\": [results[\"recall\"].mean()],\n",
    "    \"specificity\": [results[\"specificity\"].mean()],\n",
    "    \"precision\": [results[\"precision\"].mean()]     \n",
    "    } \n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
