{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f512de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from braindecode import EEGClassifier\n",
    "from braindecode.models import EEGNetv4\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from moabb.paradigms import MotorImagery\n",
    "from moabb.datasets import Zhou2016\n",
    "from braindecode import EEGClassifier\n",
    "from braindecode.models import EEGNetv4\n",
    "\n",
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "from skorch import NeuralNet\n",
    "from skorch.utils import to_numpy\n",
    "from sklearn.base import TransformerMixin\n",
    "from braindecode.models import EEGNetv4\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from moabb.paradigms import MotorImagery\n",
    "from moabb.datasets import Zhou2016\n",
    "from moabb.evaluations import WithinSessionEvaluation, CrossSessionEvaluation\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07dc1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = dict(\n",
    "    torch='torch_params.pkl',\n",
    "    f_params='skorch_params.pkl',\n",
    "    f_optimizer='skorch_opt.pkl',\n",
    "    f_history='skorch_history.json',\n",
    ")\n",
    "local_paths = {\n",
    "    k: hf_hub_download(\n",
    "        repo_id='PierreGtch/EEGNetv4',\n",
    "        filename='toy/' + name,\n",
    "    )\n",
    "    for k, name in file_names.items()\n",
    "}\n",
    "\n",
    "# load the pure pytorch module:\n",
    "torch_module = EEGNetv4(in_chans=3, n_classes=2, input_window_samples=200)\n",
    "torch_module.load_state_dict(torch.load(local_paths['torch']))\n",
    "\n",
    "# load the pure pytorch module:\n",
    "skorch_module = EEGNetv4(in_chans=3, n_classes=2, input_window_samples=200)\n",
    "skorch_classifier = EEGClassifier(skorch_module, max_epochs=5)\n",
    "skorch_classifier.initialize()\n",
    "skorch_classifier.load_params(\n",
    "    f_params=local_paths['f_params'],\n",
    "    f_optimizer=local_paths['f_optimizer'],\n",
    "    f_history=local_paths['f_history'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b1cdb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = skorch_classifier.partial_fit(X_np, y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540910d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm = MotorImagery(\n",
    "    channels=['C3', 'Cz', 'C4'],  # Same channels as used during pre-training.\n",
    "    events=['left_hand', 'right_hand', 'feet'],\n",
    "    n_classes=3,\n",
    "    fmin=0.5,\n",
    "    fmax=40,\n",
    "    tmin=0,\n",
    "    tmax=3,\n",
    "    resample=128,\n",
    ")\n",
    "datasets = [Zhou2016()]\n",
    "\n",
    "# --------------------------\n",
    "# Load data from MOABB\n",
    "# --------------------------\n",
    "# Note: get_data returns a dictionary with a key per subject.\n",
    "data = paradigm.get_data(datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b9b797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (1800, 3, 385), y shape = (1800,)\n"
     ]
    }
   ],
   "source": [
    "# For illustration, if you have a single subject's data returned as a tuple:\n",
    "X, y, metadata = data\n",
    "print(f\"X shape = {X.shape}, y shape = {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d3ebea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change y shape to one hot encoding\n",
    "one_hot_y = []\n",
    "i = 0\n",
    "for label in y:\n",
    "    if(y[i] == \"feet\"):\n",
    "        one_hot_y.append(0)\n",
    "    if(y[i] == \"left_hand\"):\n",
    "        one_hot_y.append(1)\n",
    "    if(y[i] == \"right_hand\"):\n",
    "        one_hot_y.append(2)\n",
    "    i+=1\n",
    "\n",
    "one_hot_y = np.array(one_hot_y, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd399f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_finetune, X_test, y_finetune, y_test = train_test_split(\n",
    "    X, one_hot_y, train_size=0.8, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ed8a785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning set: (1440, 3, 385), Test set: (360, 3, 385)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andresalvarezolmo/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'in_chans' is depreciated. Use 'n_chans' instead.\n",
      "  warnings.warn(\n",
      "/Users/andresalvarezolmo/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'n_classes' is depreciated. Use 'n_outputs' instead.\n",
      "  warnings.warn(\n",
      "/Users/andresalvarezolmo/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'input_window_samples' is depreciated. Use 'n_times' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.2196\u001b[0m       \u001b[32m0.2986\u001b[0m        \u001b[35m1.1155\u001b[0m  1.9757\n",
      "      2        \u001b[36m1.1597\u001b[0m       \u001b[32m0.3194\u001b[0m        \u001b[35m1.1078\u001b[0m  2.3092\n",
      "      3        \u001b[36m1.1445\u001b[0m       \u001b[32m0.3333\u001b[0m        \u001b[35m1.1035\u001b[0m  1.9662\n",
      "      4        \u001b[36m1.1191\u001b[0m       \u001b[32m0.3368\u001b[0m        \u001b[35m1.1006\u001b[0m  1.8968\n",
      "      5        \u001b[36m1.1038\u001b[0m       \u001b[32m0.3507\u001b[0m        \u001b[35m1.0990\u001b[0m  1.9140\n",
      "      6        \u001b[36m1.0931\u001b[0m       0.3507        \u001b[35m1.0978\u001b[0m  1.9681\n",
      "      7        \u001b[36m1.0798\u001b[0m       \u001b[32m0.3646\u001b[0m        \u001b[35m1.0965\u001b[0m  1.8291\n",
      "      8        \u001b[36m1.0685\u001b[0m       \u001b[32m0.3715\u001b[0m        \u001b[35m1.0956\u001b[0m  2.0896\n",
      "      9        \u001b[36m1.0643\u001b[0m       \u001b[32m0.3785\u001b[0m        \u001b[35m1.0948\u001b[0m  2.0557\n",
      "     10        \u001b[36m1.0517\u001b[0m       \u001b[32m0.3854\u001b[0m        \u001b[35m1.0935\u001b[0m  1.8978\n",
      "     11        \u001b[36m1.0342\u001b[0m       \u001b[32m0.3924\u001b[0m        \u001b[35m1.0923\u001b[0m  1.8927\n",
      "     12        \u001b[36m1.0318\u001b[0m       \u001b[32m0.3958\u001b[0m        \u001b[35m1.0911\u001b[0m  1.8460\n",
      "     13        \u001b[36m1.0188\u001b[0m       0.3854        \u001b[35m1.0893\u001b[0m  1.9451\n",
      "     14        \u001b[36m1.0013\u001b[0m       0.3889        \u001b[35m1.0873\u001b[0m  1.8029\n",
      "     15        1.0037       0.3889        \u001b[35m1.0847\u001b[0m  1.8986\n",
      "     16        \u001b[36m0.9832\u001b[0m       \u001b[32m0.4167\u001b[0m        \u001b[35m1.0808\u001b[0m  1.7950\n",
      "     17        \u001b[36m0.9703\u001b[0m       \u001b[32m0.4236\u001b[0m        \u001b[35m1.0768\u001b[0m  1.9690\n",
      "     18        \u001b[36m0.9684\u001b[0m       0.4201        \u001b[35m1.0716\u001b[0m  2.0203\n",
      "     19        \u001b[36m0.9342\u001b[0m       \u001b[32m0.4410\u001b[0m        \u001b[35m1.0650\u001b[0m  1.9104\n",
      "     20        \u001b[36m0.9197\u001b[0m       0.4410        \u001b[35m1.0578\u001b[0m  1.9757\n",
      "Test Accuracy after fine tuning on 20% of the data: 0.406\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fine-tuning set: {X_finetune.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# --------------------------\n",
    "# Assume you have a SKorch-based EEGClassifier\n",
    "# that loads a model (e.g. EEGNetv4) and its pre-trained parameters.\n",
    "# For demonstration, we assume skorch_classifier is already constructed,\n",
    "# initialized, and loaded with pre-trained parameters.\n",
    "\n",
    "# Here we build the SKorch model (adjust the parameters as needed).\n",
    "# This example builds a new instance. In your actual code, you might load it as you did earlier.\n",
    "skorch_module = EEGNetv4(in_chans=3, n_classes=3, input_window_samples=X.shape[-1])\n",
    "skorch_classifier = EEGClassifier(skorch_module, max_epochs=20)\n",
    "\n",
    "# Initialize the SKorch model (and optionally load pre-trained parameters)\n",
    "skorch_classifier.initialize()\n",
    "# If you have pre-trained parameters, load them here:\n",
    "# skorch_classifier.load_params(f_params=..., f_optimizer=..., f_history=...)\n",
    "\n",
    "# Optional: Ensure that the entire model is trainable (full fine tuning)\n",
    "# for param in skorch_classifier.module_.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# --------------------------\n",
    "# Fine Tune on 20% of the Data Using partial_fit\n",
    "# --------------------------\n",
    "# NEW: Fine tuning the entire model on only 20% of the data.\n",
    "_ = skorch_classifier.partial_fit(X_finetune, y_finetune)\n",
    "\n",
    "# --------------------------\n",
    "# Evaluate on the Remaining 80%\n",
    "# --------------------------\n",
    "y_pred = skorch_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy after fine tuning on 20% of the data: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86d13f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_clf_layers(model: nn.Sequential):\n",
    "    \"\"\"\n",
    "    Remove the classification layers from braindecode models.\n",
    "    Tested on EEGNetv4, Deep4Net (i.e. DeepConvNet), and EEGResNet.\n",
    "    \"\"\"\n",
    "    new_layers = []\n",
    "    for name, layer in model.named_children():\n",
    "        if 'classif' in name:\n",
    "            continue\n",
    "        if 'softmax' in name:\n",
    "            continue\n",
    "        new_layers.append((name, layer))\n",
    "    return nn.Sequential(OrderedDict(new_layers))\n",
    "\n",
    "\n",
    "def freeze_model(model):\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "class FrozenNeuralNetTransformer(NeuralNet, TransformerMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            *args,\n",
    "            criterion=nn.MSELoss,  # should be unused\n",
    "            unique_name=None,  # needed for a unique digest in MOABB\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            criterion=criterion,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.initialize()\n",
    "        self.unique_name = unique_name\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self  # do nothing\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.infer(X)\n",
    "        return to_numpy(X)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return super().__repr__() + self.unique_name\n",
    "    \n",
    "def flatten_batched(X):\n",
    "    return X.reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0eeb70a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andresalvarezolmo/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'in_chans' is depreciated. Use 'n_chans' instead.\n",
      "  warnings.warn(\n",
      "/Users/andresalvarezolmo/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'n_classes' is depreciated. Use 'n_outputs' instead.\n",
      "  warnings.warn(\n",
      "/Users/andresalvarezolmo/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/braindecode/models/base.py:23: UserWarning: EEGNetv4: 'input_window_samples' is depreciated. Use 'n_times' instead.\n",
      "  warnings.warn(\n",
      "<moabb.datasets.alex_mi.AlexMI object at 0x166e26140> not compatible with paradigm. Removing this dataset from the list.\n",
      "<moabb.datasets.bnci.BNCI2014_002 object at 0x166e27be0> not compatible with paradigm. Removing this dataset from the list.\n",
      "<moabb.datasets.bnci.BNCI2014_004 object at 0x166e26d70> not compatible with paradigm. Removing this dataset from the list.\n",
      "<moabb.datasets.bnci.BNCI2015_001 object at 0x166e26500> not compatible with paradigm. Removing this dataset from the list.\n",
      "<moabb.datasets.bnci.BNCI2015_004 object at 0x166e27880> not compatible with paradigm. Removing this dataset from the list.\n",
      "<moabb.datasets.gigadb.Cho2017 object at 0x166e269e0> not compatible with paradigm. Removing this dataset from the list.\n",
      "<moabb.datasets.mpi_mi.GrosseWentrup2009 object at 0x166e27b50> not compatible with paradigm. Removing this dataset from the list.\n",
      "<moabb.datasets.Lee2019.Lee2019_MI object at 0x166e25c90> not compatible with paradigm. Removing this dataset from the list.\n",
      "<moabb.datasets.liu2024.Liu2024 object at 0x166e271f0> not compatible with paradigm. Removing this dataset from the list.\n",
      "<moabb.datasets.bbci_eeg_fnirs.Shin2017A object at 0x166e26ec0> not compatible with paradigm. Removing this dataset from the list.\n",
      "<moabb.datasets.stieger2021.Stieger2021 object at 0x166e25e70> not compatible with paradigm. Removing this dataset from the list.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 56\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Use the pipeline\u001b[39;00m\n\u001b[1;32m     50\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m WithinSessionEvaluation(\n\u001b[1;32m     51\u001b[0m     paradigm\u001b[38;5;241m=\u001b[39mparadigm,\n\u001b[1;32m     52\u001b[0m     hdf5_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     53\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 56\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipelines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdemo_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msklearn_pipeline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpostprocess_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_data\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/evaluations/base.py:222\u001b[0m, in \u001b[0;36mBaseEvaluation.process\u001b[0;34m(self, pipelines, param_grid, postprocess_pipeline)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets:\n\u001b[1;32m    221\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing dataset: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dataset\u001b[38;5;241m.\u001b[39mcode))\n\u001b[0;32m--> 222\u001b[0m     process_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparadigm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_process_pipelines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_raws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_raws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpostprocess_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpostprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# (we only keep the pipeline for the first frequency band, better ideas?)\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m    231\u001b[0m         dataset,\n\u001b[1;32m    232\u001b[0m         pipelines,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m         postprocess_pipeline\u001b[38;5;241m=\u001b[39mpostprocess_pipeline,\n\u001b[1;32m    236\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/paradigms/base.py:180\u001b[0m, in \u001b[0;36mBaseProcessing.make_process_pipelines\u001b[0;34m(self, dataset, return_epochs, return_raws, postprocess_pipeline)\u001b[0m\n\u001b[1;32m    178\u001b[0m     steps\u001b[38;5;241m.\u001b[39mappend((StepType\u001b[38;5;241m.\u001b[39mEPOCHS, epochs_pipeline))\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m array_pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m     array_events_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mForkPipelines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray_pipeline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents_pipeline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     steps\u001b[38;5;241m.\u001b[39mappend((StepType\u001b[38;5;241m.\u001b[39mARRAY, array_events_pipeline))\n\u001b[1;32m    187\u001b[0m process_pipelines\u001b[38;5;241m.\u001b[39mappend(Pipeline(steps))\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/BCI-2023-Workshop_Learning-from-small-datasets/venv/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:37\u001b[0m, in \u001b[0;36mForkPipelines.__init__\u001b[0;34m(self, transformers)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, transformers: List[Tuple[\u001b[38;5;28mstr\u001b[39m, Union[Pipeline, TransformerMixin]]]):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, t \u001b[38;5;129;01min\u001b[39;00m transformers:\n\u001b[0;32m---> 37\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformers \u001b[38;5;241m=\u001b[39m transformers\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First, create the embedding from the pre-trained model\n",
    "path_kwargs = hf_hub_download(\n",
    "    repo_id='PierreGtch/EEGNetv4',\n",
    "    filename='EEGNetv4_Lee2019_MI/kwargs.pkl',\n",
    ")\n",
    "path_params = hf_hub_download(\n",
    "    repo_id='PierreGtch/EEGNetv4',\n",
    "    filename='EEGNetv4_Lee2019_MI/model-params.pkl',\n",
    ")\n",
    "\n",
    "with open(path_kwargs, 'rb') as f:\n",
    "    kwargs = pickle.load(f)\n",
    "module_cls = kwargs['module_cls']\n",
    "module_kwargs = kwargs['module_kwargs']\n",
    "\n",
    "# Load the pre-trained model\n",
    "torch_module = module_cls(**module_kwargs)\n",
    "torch_module.load_state_dict(torch.load(path_params, map_location='cpu'))\n",
    "embedding = freeze_model(remove_clf_layers(torch_module)).double()\n",
    "\n",
    "# Create a wrapper for your trained classifier to make it compatible with the pipeline\n",
    "class TrainedClassifierWrapper:\n",
    "    def __init__(self, trained_classifier):\n",
    "        self.trained_classifier = trained_classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # The classifier is already trained, so we just return self\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.trained_classifier.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.trained_classifier.predict_proba(X)\n",
    "\n",
    "# Create the pipeline using your trained classifier\n",
    "sklearn_pipeline = Pipeline([\n",
    "    ('embedding', FrozenNeuralNetTransformer(embedding, unique_name='pretrained_Lee2019')),\n",
    "    ('flatten', FunctionTransformer(flatten_batched)),\n",
    "    ('classifier', TrainedClassifierWrapper(skorch_classifier)),\n",
    "])\n",
    "\n",
    "# Optional: Add data validation\n",
    "def validate_data(X, y):\n",
    "    print(f\"Input shape before embedding: {X.shape}\")\n",
    "    # You can add more validation steps here\n",
    "    return X, y\n",
    "\n",
    "# Use the pipeline\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm,\n",
    "    hdf5_path='results.h5',\n",
    "    n_jobs=1\n",
    ")\n",
    "s\n",
    "results = evaluation.process(\n",
    "    pipelines=dict(demo_pipeline=sklearn_pipeline),\n",
    "    param_grid=None,\n",
    "    postprocess_pipeline=validate_data\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
